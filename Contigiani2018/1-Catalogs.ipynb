{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splashback.cluster import cluster_sample\n",
    "from astropy.table import Table, Column\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np \n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "from astropy import units as u\n",
    "from splashback.profile import Mvir_to_M200m, rvir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Reformat catalogs***\n",
    "\n",
    "The original source catalogs are in txt files, which can be difficult to parse. This files rewrites everything in FITS file using the same notation as in the paper. \n",
    "\n",
    "Notice that the contamination correction parameters are loaded from the original file as a correction on the sky-coordinates; this way the whole correction becomes cosmology-independent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Table.read('data/original/clusters.dat', format='ascii')\n",
    "data_planck = Table.read('data/original/m500_mega_planck.dat', format='ascii')\n",
    "\n",
    "z, xcen, ycen, mmin, mmax, da, beta_avg, r_500,  m_500, n_0, r_core, r_max = [np.zeros(len(data)) for i in xrange(12)]\n",
    "column_list = ['name', 'z', 'xcen', 'ycen', 'mmin', 'mmax', 'da', 'beta_avg', 'r_500',  'm_500', 'n_0', 'r_core', 'r_max']\n",
    "source_column_list = ['x', 'y', 'm', 'e1', 'e2', 'de', 'pg', 'mu', 'delmag', 'e1r', 'e2r']\n",
    "meta_var = {'details' : 'CCCP sample - Hoekstra+ 2015, Planck r_500, m_500'}\n",
    "name = [None]*len(data)\n",
    "da, r_500, m_500, n_0, r_core, r_max = da*u.Gpc/u.rad, r_500*u.arcsec, m_500*u.Msun, n_0*u.arcsec, r_core*u.arcsec, r_max*u.arcsec\n",
    "\n",
    "i=0\n",
    "for cluster_name in data['name_cl']:\n",
    "    print cluster_name\n",
    "    Mpc = data['Mpc'][data['name_cl']==cluster_name]\n",
    "\n",
    "    name[i] = cluster_name\n",
    "    z[i] = data['z_cl'][data['name_cl']==cluster_name]\n",
    "    xcen[i] = data['xcen'][data['name_cl']==cluster_name]\n",
    "    ycen[i] = data['ycen'][data['name_cl']==cluster_name]\n",
    "    mmin[i] = data['mmin'][data['name_cl']==cluster_name]\n",
    "    mmax[i] = data['mmax'][data['name_cl']==cluster_name]\n",
    "    da[i] = data['da'][data['name_cl']==cluster_name]*u.Gpc/u.rad\n",
    "    beta_avg[i] = data['beta_avg'][data['name_cl']==cluster_name]\n",
    "    r_500[i] = data_planck['r_d'][data_planck['name_clus']==cluster_name]*Mpc*u.arcsec\n",
    "    m_500[i] = data_planck['m_d'][data_planck['name_clus']==cluster_name]/0.7*u.Msun\n",
    "\n",
    "    data_contam = np.loadtxt('data/original/CONTAM_PAR/'+cluster_name+'.par')\n",
    "    n_0[i] = data_contam[6,4]/data_contam[6, 8]*u.arcsec\n",
    "    r_core[i] = data_contam[6,6]*Mpc*0.7*u.arcsec\n",
    "    r_max[i] = 4*Mpc*0.7*u.arcsec\n",
    "    i+=1\n",
    "\n",
    "\n",
    "    # LOAD SOURCE CATALOG\n",
    "    data_source = np.loadtxt('data/original/source_new/'+cluster_name+'.cat')\n",
    "    data_source_extra = np.loadtxt('data/original/source_old/mos_'+cluster_name+'.cat')\n",
    "\n",
    "    source_meta_var = {'NAME' : cluster_name, 'SAMPLE' : 'CCCP', 'PIXSIZE' : 0.186, 'PIXUNIT' : 'arcsec'}\n",
    "    Table_source = Table([data_source[:, 0], data_source[:, 1], data_source[:,2], data_source[:, 3], data_source[:,4], \\\n",
    "                        data_source[:, 5], data_source[:,6], data_source[:, 7], data_source[:,11], \\\n",
    "                        data_source_extra[:, 3], data_source_extra[:, 4]], names=source_column_list, meta=source_meta_var)\n",
    "    Table_source.write('data/source/'+cluster_name+'.fits', overwrite=True)\n",
    "\n",
    "\n",
    "#SAVE SAMPLE FITS TABLE\n",
    "cluster_table = Table([name, z, xcen, ycen, mmin, mmax, da, beta_avg, r_500,  m_500, n_0, r_core, r_max], names=column_list, meta=meta_var)\n",
    "cluster_table.write('data/CCCPoriginal.fits', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Update cosmology variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"data/CCCPoriginal.fits\" # CCCP original file \n",
    "N_bins = 6 # bins in magnitude\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "#Hardcoded\n",
    "dirpath = \"data/source/\" # source file\n",
    "photozpath = \"data/photoz/COSMOS2015.fits\" # redshift dist file\n",
    "noisepath = \"output/noise/\" # noise dir where to save the weighted redshift dist. \n",
    "\n",
    "#Initialize things\n",
    "CCCP = cluster_sample(filepath, dirpath)\n",
    "data_z = Table.read(photozpath)\n",
    "zlist = data_z['z'].quantity.value\n",
    "mlist = data_z['m'].quantity.value\n",
    "mbins = np.linspace(22, 25, N_bins+1)\n",
    "beta = np.zeros(len(CCCP))\n",
    "cosmo = FlatLambdaCDM(H0=70, Om0=0.3)\n",
    "\n",
    "# Average beta for a z_s_list (list of source redshifts) and z_l (lens redshift)\n",
    "def avg_beta(z_s_list, z_l):\n",
    "    temp = cosmo.angular_diameter_distance_z1z2(z_l, z_s_list)/cosmo.angular_diameter_distance(z_s_list)\n",
    "    temp[temp<0] = 0.\n",
    "    return temp.mean()\n",
    "\n",
    "# Compute beta for each cluster using magnitude weights\n",
    "for i in xrange(len(CCCP)):\n",
    "    w_avg = np.zeros(N_bins)\n",
    "    beta_bin = np.zeros(N_bins)\n",
    "    self = CCCP[i]\n",
    "    z_l = CCCP[i].z.value\n",
    "    idx = (self.m > self.mmin) & (self.m < self.mmax) & (self.pg>0.1) & (self.delmag == 0)\n",
    "    x, y, pg, de, m, mu = self.x[idx], self.y[idx], self.pg[idx], self.de[idx], self.m[idx], self.mu[idx]\n",
    "    w = pg**2./((0.25*pg)**2. + de**2.)\n",
    "    data_z_temp = Table.read(photozpath)\n",
    "    w_column = np.ones(len(data_z_temp))    \n",
    "    \n",
    "    for j in xrange(N_bins):\n",
    "        # average weight in bin\n",
    "        idx = (m >= mbins[j]) & (m < mbins[j+1])\n",
    "        w_avg[j] = w[idx].sum()/w.sum()\n",
    "        \n",
    "        \n",
    "        # average beta in bin\n",
    "        idx = (mlist>=mbins[j]) & (mlist<mbins[j+1])\n",
    "        beta_bin[j] = avg_beta(zlist[idx], z_l)    \n",
    "        w_column[idx] = w_avg[j]/idx.sum()\n",
    "    \n",
    "    beta[i] = (beta_bin*w_avg).sum()\n",
    "\n",
    "    data_z_temp.add_column(Column(w_column, name='w'))\n",
    "    data_z_temp.write(noisepath+CCCP[i].name+\".fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Divide subsamples***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_CCCP = Table.read(filepath)\n",
    "\n",
    "\n",
    "data_CCCP['da'] = cosmo.angular_diameter_distance(data_CCCP['z'])/u.rad\n",
    "\n",
    "m_g = np.array([0.60, 0.80, 0., 0.68, 0.85, 1.06, 0.65, 0.66, 1.56, 0.97, 0.75, 0., 0., 1.21, 0.99, 0.44, 0.68, 0.74, 2.33, 1.16, 0.50, 1.46, 0.86, 0.24, 1.03, 0.58, 1.63, 0.41, 2.35, 0.53, 0., 0.62, 0.61, 0.])*(1e14*u.Msun)\n",
    "m_vir = np.array([5.9, 7.0, 8.9, 7.8, 15.3, 10.7, 4.6, 9.4, 14.1, 21.4, 19.7, 8.7, 19.4, 19.9, 13.5, 13.5, 15.7, 9.4, 17.4, 19.9, 7.9, 24.4, 20.9, 3.5, 17.4, 16.3, 19.9, 6.2, 38.4, 6.5, 17.2, 12.0, 6.4, 7.6])*(1e14*u.Msun)\n",
    "off = np.array([11, 9, -1, 10, 0, 47, 14, 12, 20, 0, 39, -1, -1, 12, 0, 0.7, 10, 108, 11, 4, 75, 5, 8, 4, 34, 12, 7, 44, 113, 1, -1, 5, 14, -1])*u.kpc\n",
    "m_200 = np.zeros(len(m_vir))*u.Msun\n",
    "\n",
    "for i in xrange(len(m_vir)):\n",
    "    m_200[i] = Mvir_to_M200m(m_vir[i], data_CCCP['z'][i])\n",
    "\n",
    "idx = (m_g == 0.)\n",
    "z = data_CCCP['z']\n",
    "m_500 = data_CCCP['m_500'].quantity\n",
    "Ez = np.sqrt(0.3*(1.+z.quantity)**3. +0.7)\n",
    "\n",
    "m_g[idx] = ( (m_500*Ez)[idx]/(1e14*u.Msun) /(10**0.9) )**(1./1.04) /Ez[idx] * (1e14*u.Msun)\n",
    "\n",
    "print \"Special Mgas:\"\n",
    "print data_CCCP['name'][idx]\n",
    "\n",
    "data_CCCP.add_column(Column(m_g, name='m_g'))\n",
    "data_CCCP.add_column(Column(beta, name='beta'))\n",
    "data_CCCP.add_column(Column(m_200, name='m_200'))\n",
    "data_CCCP.add_column(Column(m_vir, name='m_vir'))\n",
    "data_CCCP.add_column(Column(off, name='off'))\n",
    "\n",
    "data_CCCP = data_CCCP['name', 'xcen', 'ycen', 'mmin', 'mmax', 'n_0', 'r_core', 'r_max', 'r_500', 'm_500', 'm_200', 'm_vir', 'm_g', 'z', 'da', 'beta', 'off']\n",
    "data_CCCP.write('data/CCCP.fits', overwrite=True)\n",
    "\n",
    "data_CCCP = Table.read('data/CCCP.fits')\n",
    "idx = (data_CCCP['name'] != \"A115S\") & (data_CCCP['name'] != \"A115N\") & (data_CCCP['name'] != \"A223S\") &  (data_CCCP['name'] != \"A223N\") & (data_CCCP['name'] != \"MACS0717\") & (data_CCCP['name'] != \"A222\") & (data_CCCP['name'] != \"A1758\") \n",
    "data_CCCP = data_CCCP[idx]\n",
    "data_CCCP.write('data/CCCPnomergers.fits', overwrite=True)\n",
    "\n",
    "data_CCCP = Table.read('data/CCCPnomergers.fits')\n",
    "idx = (data_CCCP['z'] > 0.25)\n",
    "data_CCCP = data_CCCP[idx]\n",
    "data_CCCP.write('data/CCCPhighz.fits', overwrite=True)\n",
    "\n",
    "data_CCCP = Table.read('data/CCCPnomergers.fits')\n",
    "idx = data_CCCP['m_g'].quantity > 8e13*u.Msun\n",
    "data_CCCP = data_CCCP[idx]\n",
    "data_CCCP.write('data/CCCPhighm.fits', overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Prepare files for intrinsic covariance matrix***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "bin_edges = np.geomspace(.2, 9, 11)*u.Mpc\n",
    "z_bin_edges = np.around(np.linspace(0.005, 5.995, 600), 5)\n",
    "\n",
    "#------------------------------------------\n",
    "data_CCCP = Table.read('data/CCCPnomergers.fits')\n",
    "filep = open(\"output/noise/CCCP.tab\", \"w+\")\n",
    "for i in xrange(len(data_CCCP)):\n",
    "    print data_CCCP['name'][i]\n",
    "    # Write entry in main file\n",
    "    filep.write(data_CCCP['name'][i]+\" \"+str(np.around(data_CCCP['z'][i], 2))+\" \"+data_CCCP['name'][i]+\"_pz annuli\"+data_CCCP['name'][i]+\"\\n\")\n",
    "    \n",
    "    # Generate annuli file\n",
    "    file_annuli = open(\"output/noise/annuli\"+data_CCCP['name'][i]+\".tab\", \"w+\")\n",
    "    bin_edges_sky = ( bin_edges/data_CCCP['da'].quantity[i] ).to('arcmin').value\n",
    "    file_annuli.write(str(len(bin_edges_sky)-1)+\"\\n\")\n",
    "    for j in xrange(len(bin_edges_sky)-1):\n",
    "        file_annuli.write(str(np.around(bin_edges_sky[j], 5))+\" \"+str( np.around(bin_edges_sky[j+1], 5))+\"\\n\")\n",
    "    file_annuli.close()\n",
    "    \n",
    "    # Generate photometric redshift file\n",
    "    file_pz = open(\"output/noise/\"+data_CCCP['name'][i]+\"_pz.tab\", \"w+\")\n",
    "    file_pz.write(\"#hist\\n\")\n",
    "    #file_pz.write(str(np.around(z_bin_edges[0], 5))+\" \"+str(np.around(z_bin_edges[-1], 5))+\"\\n\")\n",
    "    data_z = Table.read(\"data/photoz/individual/\"+data_CCCP['name'][i]+\".fits\")\n",
    "    zlist = data_z['z']\n",
    "    wlist = data_z['w']\n",
    "    for j in xrange(len(z_bin_edges)-1):\n",
    "        idx = (zlist < z_bin_edges[j+1]) & (zlist >= z_bin_edges[j])\n",
    "        value = np.around(wlist[idx].sum(), 15)\n",
    "        file_pz.write(str(z_bin_edges[j])+\" \"+format(value, '.15f')+\"\\n\")\n",
    "    file_pz.write(str(z_bin_edges[-1])+\" 0\\n\")\n",
    "    file_pz.close()\n",
    "filep.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
